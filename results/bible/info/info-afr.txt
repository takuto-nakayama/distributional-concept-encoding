Analysis began: 09:45:01.

-----initial settings-----
data source: bibles/FullText/Afrikaans.txt
project id: bible
data id: afr
data length: 31163 lines
mode: path
tokenizer: bert-base-cased
model: bert-base-cased
gpu: yes
batch: 20
min_data for each subword: 1000
sample number for entropy: 1000


------result summary------
data amount: 251 subwords
entropy: 7.085544304560666